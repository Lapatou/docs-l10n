{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pmxv2ioyCRw"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "b-2ShX25yNWf"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa49bUnKyRgF"
      },
      "source": [
        "# 시계열 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Ilg92myRcw"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/time_series\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a>   </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행</a>   </td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a>   </td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU8C5qm_4vZb"
      },
      "source": [
        "이 튜토리얼에서는 TensorFlow를 사용한 시계열 예측을 소개합니다. Convolutional/Recurrent Neural Network(CNN 및 RNN)를 포함하여 몇 가지 다른 스타일의 모델을 빌드합니다.\n",
        "\n",
        "이 내용은 각각 하위 항목이 있는 두 부분으로 나누어 생각합니다.\n",
        "\n",
        "- 단일 타임스텝 예측:\n",
        "    - 단일 특성\n",
        "    - 모든 특성\n",
        "- 다중 스텝 예측:\n",
        "    - 싱글샷: 모두 한 번에 예측합니다.\n",
        "    - 자가 회귀: 한 번에 하나의 예측을 수행하고 결과를 모델로 피드백합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVhK72Pu1cJL"
      },
      "source": [
        "## 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rZnJaGTWQw0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TokBlnUhWFw9"
      },
      "source": [
        "## 날씨 데이터세트\n",
        "\n",
        "이 튜토리얼은 <a class=\"external\" href=\"https://www.bgc-jena.mpg.de/wetter/\">막스 플랑크 생물 지구화학 연구소</a>에서 기록한 <a class=\"external\" href=\"https://www.bgc-jena.mpg.de\">날씨 시계열 데이터세트</a>를 사용합니다.\n",
        "\n",
        "이 데이터세트에는 온도, 대기압 및 습도와 같은 14가지 특성이 있습니다. 이러한 데이터는 2003년부터 시작해 10분 간격으로 수집되었습니다. 효율성을 위해 2009년과 2016년 사이에 수집된 데이터만 사용하겠습니다. 이 데이터세트 부분은 François Chollet이 자신이 저술한 책 [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)을 위해 준비했습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyv_i85IWInT"
      },
      "outputs": [],
      "source": [
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True)\n",
        "csv_path, _ = os.path.splitext(zip_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R81Wx8WP4c3G"
      },
      "source": [
        "This tutorial will just deal with **hourly predictions**, so start by sub-sampling the data from 10-minute intervals to one-hour intervals:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX6uGeeeWIkG"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(csv_path)\n",
        "# Slice [start:stop:step], starting from index 5 take every 6th record.\n",
        "df = df[5::6]\n",
        "\n",
        "date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdbOWXiTWM2T"
      },
      "source": [
        "데이터를 살펴보겠습니다. 다음은 처음 몇 개의 행입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojHE-iCCWIhz"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRzj1inMfgcO"
      },
      "source": [
        "Here is the evolution of a few features over time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg5XIc5tfNlG"
      },
      "outputs": [],
      "source": [
        "plot_cols = ['T (degC)', 'p (mbar)', 'rho (g/m**3)']\n",
        "plot_features = df[plot_cols]\n",
        "plot_features.index = date_time\n",
        "_ = plot_features.plot(subplots=True)\n",
        "\n",
        "plot_features = df[plot_cols][:480]\n",
        "plot_features.index = date_time[:480]\n",
        "_ = plot_features.plot(subplots=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXWLG0_WBhZS"
      },
      "source": [
        "### 검사 및 정리하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhmZXJew6GlS"
      },
      "source": [
        "Next, look at the statistics of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h510pgKVrrai"
      },
      "outputs": [],
      "source": [
        "df.describe().transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzOTnWOoWMGK"
      },
      "source": [
        "#### 풍속"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i47LiW5DCVsP"
      },
      "source": [
        "One thing that should stand out is the `min` value of the wind velocity (`wv (m/s)`) and the maximum value (`max. wv (m/s)`) columns. This `-9999` is likely erroneous.\n",
        "\n",
        "There's a separate wind direction column, so the velocity should be greater than zero (`>=0`). Replace it with zeros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFOq0_80vF4d"
      },
      "outputs": [],
      "source": [
        "wv = df['wv (m/s)']\n",
        "bad_wv = wv == -9999.0\n",
        "wv[bad_wv] = 0.0\n",
        "\n",
        "max_wv = df['max. wv (m/s)']\n",
        "bad_max_wv = max_wv == -9999.0\n",
        "max_wv[bad_max_wv] = 0.0\n",
        "\n",
        "# The above inplace edits are reflected in the DataFrame.\n",
        "df['wv (m/s)'].min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtmu2IBPgPG8"
      },
      "source": [
        "### 특성 엔지니어링\n",
        "\n",
        "Before diving in to build a model, it's important to understand your data and be sure that you're passing the model appropriately formatted data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYyEaqiD6j4s"
      },
      "source": [
        "#### 바람\n",
        "\n",
        "The last column of the data, `wd (deg)`—gives the wind direction in units of degrees. Angles do not make good model inputs: 360° and 0° should be close to each other and wrap around smoothly. Direction shouldn't matter if the wind is not blowing.\n",
        "\n",
        "현재, 바람 데이터의 분포는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO7JGTcWQG2z"
      },
      "outputs": [],
      "source": [
        "plt.hist2d(df['wd (deg)'], df['wv (m/s)'], bins=(50, 50), vmax=400)\n",
        "plt.colorbar()\n",
        "plt.xlabel('Wind Direction [deg]')\n",
        "plt.ylabel('Wind Velocity [m/s]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWnf5dwMU1_g"
      },
      "source": [
        "그러나 풍향과 속도 열을 바람 **벡터**로 변환하면 모델이 해석하기가 더 쉽습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GmSTHXw6lI1"
      },
      "outputs": [],
      "source": [
        "wv = df.pop('wv (m/s)')\n",
        "max_wv = df.pop('max. wv (m/s)')\n",
        "\n",
        "# Convert to radians.\n",
        "wd_rad = df.pop('wd (deg)')*np.pi / 180\n",
        "\n",
        "# Calculate the wind x and y components.\n",
        "df['Wx'] = wv*np.cos(wd_rad)\n",
        "df['Wy'] = wv*np.sin(wd_rad)\n",
        "\n",
        "# Calculate the max wind x and y components.\n",
        "df['max Wx'] = max_wv*np.cos(wd_rad)\n",
        "df['max Wy'] = max_wv*np.sin(wd_rad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iI0zDoxWDyB"
      },
      "source": [
        "The distribution of wind vectors is much simpler for the model to correctly interpret:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMgCG5o2SYKD"
      },
      "outputs": [],
      "source": [
        "plt.hist2d(df['Wx'], df['Wy'], bins=(50, 50), vmax=400)\n",
        "plt.colorbar()\n",
        "plt.xlabel('Wind X [m/s]')\n",
        "plt.ylabel('Wind Y [m/s]')\n",
        "ax = plt.gca()\n",
        "ax.axis('tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8im1ttOWlRB"
      },
      "source": [
        "#### 시간"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YE21HKK40zQ"
      },
      "source": [
        "Similarly, the `Date Time` column is very useful, but not in this string form. Start by converting it to seconds:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIFf-VjMfnh3"
      },
      "outputs": [],
      "source": [
        "timestamp_s = date_time.map(pd.Timestamp.timestamp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC_pnM1D5Sgc"
      },
      "source": [
        "Similar to the wind direction, the time in seconds is not a useful model input. Being weather data, it has clear daily and yearly periodicity. There are many ways you could deal with periodicity.\n",
        "\n",
        "You can get usable signals by using sine and cosine transforms to clear \"Time of day\" and \"Time of year\" signals:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBfX6CDwax73"
      },
      "outputs": [],
      "source": [
        "day = 24*60*60\n",
        "year = (365.2425)*day\n",
        "\n",
        "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
        "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
        "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
        "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXBbTJZfuuTC"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.array(df['Day sin'])[:25])\n",
        "plt.plot(np.array(df['Day cos'])[:25])\n",
        "plt.xlabel('Time [h]')\n",
        "plt.title('Time of day signal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiurzTGQgf_D"
      },
      "source": [
        "그러면 모델이 가장 중요한 빈도 특성에 액세스할 수 있습니다. 이 경우 어떤 빈도가 중요한지 미리 알고 있었습니다.\n",
        "\n",
        "해당 정보가 없는 경우 <a href=\"https://en.wikipedia.org/wiki/Fast_Fourier_transform\" class=\"external\">고속 푸리에 변환</a>을 사용하여 특성을 추출하여 중요한 빈도를 결정할 수 있습니다. 가정을 확인하기 위해 시간 경과에 따른 온도의 `tf.signal.rfft`가 있습니다. `1/year` 및 `1/day`에 가까운 빈도에서 명백한 피크가 있다는 점에 주목하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN4U1fcMiTYs"
      },
      "outputs": [],
      "source": [
        "fft = tf.signal.rfft(df['T (degC)'])\n",
        "f_per_dataset = np.arange(0, len(fft))\n",
        "\n",
        "n_samples_h = len(df['T (degC)'])\n",
        "hours_per_year = 24*365.2524\n",
        "years_per_dataset = n_samples_h/(hours_per_year)\n",
        "\n",
        "f_per_year = f_per_dataset/years_per_dataset\n",
        "plt.step(f_per_year, np.abs(fft))\n",
        "plt.xscale('log')\n",
        "plt.ylim(0, 400000)\n",
        "plt.xlim([0.1, max(plt.xlim())])\n",
        "plt.xticks([1, 365.2524], labels=['1/Year', '1/day'])\n",
        "_ = plt.xlabel('Frequency (log scale)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rbL8bSGDHy3"
      },
      "source": [
        "### 데이터 분할"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoFJZmXBaxCc"
      },
      "source": [
        "You'll use a `(70%, 20%, 10%)` split for the training, validation, and test sets. Note the data is **not** being randomly shuffled before splitting. This is for two reasons:\n",
        "\n",
        "1. 데이터를 연속된 샘플의 창으로 자르는 것이 여전히 가능합니다.\n",
        "2. It ensures that the validation/test results are more realistic, being evaluated on the data collected after the model was trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ia-MPAHxbInX"
      },
      "outputs": [],
      "source": [
        "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
        "\n",
        "n = len(df)\n",
        "train_df = df[0:int(n*0.7)]\n",
        "val_df = df[int(n*0.7):int(n*0.9)]\n",
        "test_df = df[int(n*0.9):]\n",
        "\n",
        "num_features = df.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eFckdUUHWmT"
      },
      "source": [
        "### 데이터 정규화\n",
        "\n",
        "신경망을 훈련하기 전에 특성의 크기를 정하는 것이 중요합니다. 정규화는 평균을 빼고 각 특성의 표준 편차로 나누어 크기 조정을 수행하는 일반적인 방법입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxbIic5TMlxx"
      },
      "source": [
        "모델이 검증 및 테스트 세트의 값에 액세스할 수 없도록 훈련 데이터를 사용해서만 평균 및 표준 편차를 계산해야 합니다.\n",
        "\n",
        "또한 모델이 훈련할 때 훈련 세트의 미래 값에 액세스할 수 없어야 하고 이 정규화가 이동 평균을 사용하여 수행되어야 한다고 말할 수도 있습니다. 이 내용은 본 튜토리얼의 중점 사항이 아니며, 검증 및 테스트 세트가 있기 때문에 (다소) 정직한 메트릭을 얻을 수 있습니다. 따라서 단순화를 위해 이 튜토리얼에서는 단순 평균을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eji6njXvHusN"
      },
      "outputs": [],
      "source": [
        "train_mean = train_df.mean()\n",
        "train_std = train_df.std()\n",
        "\n",
        "train_df = (train_df - train_mean) / train_std\n",
        "val_df = (val_df - train_mean) / train_std\n",
        "test_df = (test_df - train_mean) / train_std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6ufs8kk9JQw"
      },
      "source": [
        "이제 특성의 분포를 살펴봅니다. 일부 특성은 꼬리가 길지만 `-9999` 풍속 값과 같은 명백한 오류는 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0UYEnkwm8Fe"
      },
      "outputs": [],
      "source": [
        "df_std = (df - train_mean) / train_std\n",
        "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
        "_ = ax.set_xticklabels(df.keys(), rotation=90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBBmdxZ2HgfJ"
      },
      "source": [
        "## 데이터 창 작업\n",
        "\n",
        "이 튜토리얼의 모델은 데이터의 연속된 샘플 창을 기반으로 일련의 예측을 수행합니다.\n",
        "\n",
        "입력 창의 주요 특성은 다음과 같습니다.\n",
        "\n",
        "- The width (number of time steps) of the input and label windows.\n",
        "- 각 사이의 시간 오프셋\n",
        "- 입력, 레이블 또는 둘 모두로 사용되는 특성\n",
        "\n",
        "이 튜토리얼은 다양한 모델(선형, DNN, CNN 및 RNN 모델 포함)을 빌드하고 다음 두 가지 목적으로 이 모델을 사용합니다.\n",
        "\n",
        "- *단일 출력* 및 *다중 출력* 예측\n",
        "- *단일 타임스텝* 및 *다중 타임스텝* 예측\n",
        "\n",
        "이 섹션에서는 모든 모델에 재사용할 수 있도록 데이터 창 작업을 구현하는 부분에 중점을 둡니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAhGUVx1jtOy"
      },
      "source": [
        "작업 및 모델 유형에 따라 다양한 데이터 창을 생성할 수 있습니다. 다음은 몇 가지 예입니다.\n",
        "\n",
        "1. For example, to make a single prediction 24 hours into the future, given 24 hours of history, you might define a window like this:\n",
        "\n",
        "![One prediction 24h into the future.](images/raw_window_24h.png)\n",
        "\n",
        "1. A model that makes a prediction one hour into the future, given six hours of history, would need a window like this:\n",
        "\n",
        "![One prediction 1h into the future.](images/raw_window_1h.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa2BbfNZt8wy"
      },
      "source": [
        "이 섹션의 나머지 부분에서는 `WindowGenerator` 클래스를 정의합니다. 이 클래스는 다음을 수행할 수 있습니다.\n",
        "\n",
        "1. 위의 다이어그램과 같이 인덱스와 오프셋을 처리합니다.\n",
        "2. Split windows of features into `(features, labels)` pairs.\n",
        "3. 결과 창의 내용을 플롯합니다.\n",
        "4. `tf.data.Dataset`를 사용하여 훈련, 평가 및 테스트 데이터로부터 이러한 창을 여러 배치로 효율적으로 생성합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfx3jGjyziUF"
      },
      "source": [
        "### 1. 인덱스 및 오프셋\n",
        "\n",
        "우선 `WindowGenerator` 클래스를 만듭니다. `__init__` 메서드에는 입력 및 레이블 인덱스에 필요한 모든 논리가 포함됩니다.\n",
        "\n",
        "It also takes the training, evaluation, and test DataFrames as input. These will be converted to `tf.data.Dataset`s of windows later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kem30j8QHxyW"
      },
      "outputs": [],
      "source": [
        "class WindowGenerator():\n",
        "  def __init__(self, input_width, label_width, shift,\n",
        "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
        "               label_columns=None):\n",
        "    # Store the raw data.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    # Work out the label column indices.\n",
        "    self.label_columns = label_columns\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVJgblsYzL1g"
      },
      "source": [
        "이 섹션의 시작 부분에서 다이어그램에 나타낸 두 개의 창을 만드는 코드는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsM5kRkz0UwK"
      },
      "outputs": [],
      "source": [
        "w1 = WindowGenerator(input_width=24, label_width=1, shift=24,\n",
        "                     label_columns=['T (degC)'])\n",
        "w1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viwKsYeAKFUn"
      },
      "outputs": [],
      "source": [
        "w2 = WindowGenerator(input_width=6, label_width=1, shift=1,\n",
        "                     label_columns=['T (degC)'])\n",
        "w2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJaUyTWQJd-L"
      },
      "source": [
        "### 2. 분할\n",
        "\n",
        "Given a list of consecutive inputs, the `split_window` method will convert them to a window of inputs and a window of labels.\n",
        "\n",
        "The example `w2` you define earlier will be split like this:\n",
        "\n",
        "![The initial window is all consecuitive samples, this splits it into an (inputs, labels) pairs](https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tutorials/structured_data/images/split_window.png?raw=true)\n",
        "\n",
        "이 다이어그램에는 데이터의 `features` 축이 나와 있지 않지만 이 `split_window` 함수는 단일 출력과 다중 출력 예에서 모두 사용될 수 있도록 `label_columns`를 처리합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4KbxfzqkXPW"
      },
      "outputs": [],
      "source": [
        "def split_window(self, features):\n",
        "  inputs = features[:, self.input_slice, :]\n",
        "  labels = features[:, self.labels_slice, :]\n",
        "  if self.label_columns is not None:\n",
        "    labels = tf.stack(\n",
        "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "        axis=-1)\n",
        "\n",
        "  # Slicing doesn't preserve static shape information, so set the shapes\n",
        "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "  inputs.set_shape([None, self.input_width, None])\n",
        "  labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "  return inputs, labels\n",
        "\n",
        "WindowGenerator.split_window = split_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6U6VtVuM15s"
      },
      "source": [
        "다음을 사용해 보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeCWbq6KLmL7"
      },
      "outputs": [],
      "source": [
        "# Stack three slices, the length of the total window.\n",
        "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
        "                           np.array(train_df[100:100+w2.total_window_size]),\n",
        "                           np.array(train_df[200:200+w2.total_window_size])])\n",
        "\n",
        "example_inputs, example_labels = w2.split_window(example_window)\n",
        "\n",
        "print('All shapes are: (batch, time, features)')\n",
        "print(f'Window shape: {example_window.shape}')\n",
        "print(f'Inputs shape: {example_inputs.shape}')\n",
        "print(f'Labels shape: {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtMk1ffk2Mmd"
      },
      "source": [
        "일반적으로 TensorFlow의 데이터는 가장 바깥 쪽 인덱스가 여러 예제(\"배치\" 차원)에 걸쳐 있는 배열로 구성됩니다. 중간 인덱스는 \"시간\" 또는 \"공간\"(너비, 높이) 차원입니다. 가장 안쪽 인덱스는 특성입니다.\n",
        "\n",
        "The code above took a batch of three 7-time step windows with 19 features at each time step. It splits them into a batch of 6-time step 19-feature inputs, and a 1-time step 1-feature label. The label only has one feature because the `WindowGenerator` was initialized with `label_columns=['T (degC)']`. Initially, this tutorial will build models that predict single output labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFZukGXrJoGo"
      },
      "source": [
        "### 3. 플롯하기\n",
        "\n",
        "다음은 분할 창을 간단하게 시각화할 수 있는 플롯 메서드입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmgd1qkYUWT7"
      },
      "outputs": [],
      "source": [
        "w2.example = example_inputs, example_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIrYccI-Hm3B"
      },
      "outputs": [],
      "source": [
        "def plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n",
        "  inputs, labels = self.example\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plot_col_index = self.column_indices[plot_col]\n",
        "  max_n = min(max_subplots, len(inputs))\n",
        "  for n in range(max_n):\n",
        "    plt.subplot(max_n, 1, n+1)\n",
        "    plt.ylabel(f'{plot_col} [normed]')\n",
        "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
        "             label='Inputs', marker='.', zorder=-10)\n",
        "\n",
        "    if self.label_columns:\n",
        "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
        "    else:\n",
        "      label_col_index = plot_col_index\n",
        "\n",
        "    if label_col_index is None:\n",
        "      continue\n",
        "\n",
        "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
        "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "    if model is not None:\n",
        "      predictions = model(inputs)\n",
        "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
        "                  marker='X', edgecolors='k', label='Predictions',\n",
        "                  c='#ff7f0e', s=64)\n",
        "\n",
        "    if n == 0:\n",
        "      plt.legend()\n",
        "\n",
        "  plt.xlabel('Time [h]')\n",
        "\n",
        "WindowGenerator.plot = plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXvctEuK68vX"
      },
      "source": [
        "이 플롯은 항목이 참조하는 시간을 기준으로 입력, 레이블 및 (나중에) 예측값을 정렬합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjTqUnglOOni"
      },
      "outputs": [],
      "source": [
        "w2.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqiqcPOldPG6"
      },
      "source": [
        "다른 열을 플롯할 수 있지만 예제 창 `w2` 구성에는 `T (degC)` 열에 대한 레이블만 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBRe4wnlfCH8"
      },
      "outputs": [],
      "source": [
        "w2.plot(plot_col='p (mbar)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCvD-UaUzYMw"
      },
      "source": [
        "### 4. `tf.data.Dataset` 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLO3SFR9Osdf"
      },
      "source": [
        "Finally, this `make_dataset` method will take a time series DataFrame and convert it to a `tf.data.Dataset` of `(input_window, label_window)` pairs using the `tf.keras.utils.timeseries_dataset_from_array` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35qoSQeRVfJg"
      },
      "outputs": [],
      "source": [
        "def make_dataset(self, data):\n",
        "  data = np.array(data, dtype=np.float32)\n",
        "  ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "      data=data,\n",
        "      targets=None,\n",
        "      sequence_length=self.total_window_size,\n",
        "      sequence_stride=1,\n",
        "      shuffle=True,\n",
        "      batch_size=32,)\n",
        "\n",
        "  ds = ds.map(self.split_window)\n",
        "\n",
        "  return ds\n",
        "\n",
        "WindowGenerator.make_dataset = make_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvsxQwJaCift"
      },
      "source": [
        "The `WindowGenerator` object holds training, validation, and test data.\n",
        "\n",
        "Add properties for accessing them as `tf.data.Dataset`s using the `make_dataset` method you defined earlier. Also, add a standard example batch for easy access and plotting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jZ2KkqGCfzu"
      },
      "outputs": [],
      "source": [
        "@property\n",
        "def train(self):\n",
        "  return self.make_dataset(self.train_df)\n",
        "\n",
        "@property\n",
        "def val(self):\n",
        "  return self.make_dataset(self.val_df)\n",
        "\n",
        "@property\n",
        "def test(self):\n",
        "  return self.make_dataset(self.test_df)\n",
        "\n",
        "@property\n",
        "def example(self):\n",
        "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "  result = getattr(self, '_example', None)\n",
        "  if result is None:\n",
        "    # No example batch was found, so get one from the `.train` dataset\n",
        "    result = next(iter(self.train))\n",
        "    # And cache it for next time\n",
        "    self._example = result\n",
        "  return result\n",
        "\n",
        "WindowGenerator.train = train\n",
        "WindowGenerator.val = val\n",
        "WindowGenerator.test = test\n",
        "WindowGenerator.example = example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF_Vj6Iw3Y2w"
      },
      "source": [
        "이제 `WindowGenerator` 객체가 `tf.data.Dataset` 객체에 대한 액세스 권한을 부여하므로 데이터를 쉽게 반복할 수 있습니다.\n",
        "\n",
        "The `Dataset.element_spec` property tells you the structure, data types, and shapes of the dataset elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daJ0-U383YVs"
      },
      "outputs": [],
      "source": [
        "# Each element is an (inputs, label) pair.\n",
        "w2.train.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKTx3_Z7ua-n"
      },
      "source": [
        "`Dataset`를 반복하면 구체적인 배치가 생성됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gtKXEgf4Iml"
      },
      "outputs": [],
      "source": [
        "for example_inputs, example_labels in w2.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyuGuJUgjUK3"
      },
      "source": [
        "## 단일 스텝 모델\n",
        "\n",
        "The simplest model you can build on this sort of data is one that predicts a single feature's value—1 time step (one hour) into the future based only on the current conditions.\n",
        "\n",
        "So, start by building models to predict the `T (degC)` value one hour into the future.\n",
        "\n",
        "![Predict the next time step](images/narrow_window.png)\n",
        "\n",
        "다음과 같은 단일 스텝 `(input, label)` 쌍을 생성하도록 `WindowGenerator` 객체를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5QX1G1JTPCr"
      },
      "outputs": [],
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    input_width=1, label_width=1, shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "single_step_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKTm8ajVGw4N"
      },
      "source": [
        "`window` 객체는 훈련, 검증 및 테스트 세트로부터 `tf.data.Datasets`를 생성하므로 데이터 배치를 쉽게 반복할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do4ILUaBF8oc"
      },
      "outputs": [],
      "source": [
        "for example_inputs, example_labels in single_step_window.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1bbPiR3VAm_"
      },
      "source": [
        "### 기준\n",
        "\n",
        "훈련 가능한 모델을 빌드하기 전에 나중에 더 복잡한 모델과 비교하기 위한 포인트로 성능 기준을 갖는 것이 좋습니다.\n",
        "\n",
        "This first task is to predict temperature one hour into the future, given the current value of all features. The current values include the current temperature.\n",
        "\n",
        "따라서 예측으로 현재 온도를 반환하여 \"변화 없음\"을 예측하는 모델로 시작하겠습니다. 온도가 천천히 변하기 때문에 이것은 합리적인 기준입니다. 물론, 더 미래로 들어가면 이 기준의 예측 효과를 떨어질 것입니다.\n",
        "\n",
        "![Send the input to the output](images/baseline.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TybQaIsi3yg"
      },
      "outputs": [],
      "source": [
        "class Baseline(tf.keras.Model):\n",
        "  def __init__(self, label_index=None):\n",
        "    super().__init__()\n",
        "    self.label_index = label_index\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if self.label_index is None:\n",
        "      return inputs\n",
        "    result = inputs[:, :, self.label_index]\n",
        "    return result[:, :, tf.newaxis]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vb3f948i8p8"
      },
      "source": [
        "이 모델을 인스턴스화하고 평가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS3-QKc4sX0D"
      },
      "outputs": [],
      "source": [
        "baseline = Baseline(label_index=column_indices['T (degC)'])\n",
        "\n",
        "baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                 metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "val_performance = {}\n",
        "performance = {}\n",
        "val_performance['Baseline'] = baseline.evaluate(single_step_window.val)\n",
        "performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhBxQcCSs7Ec"
      },
      "source": [
        "몇 가지 성능 메트릭을 출력했지만 모델이 얼마나 잘 동작하는지에 대한 느낌은 주지 않습니다.\n",
        "\n",
        "The `WindowGenerator` has a plot method, but the plots won't be very interesting with only a single sample.\n",
        "\n",
        "So, create a wider `WindowGenerator` that generates windows 24 hours of consecutive inputs and labels at a time. The new `wide_window` variable doesn't change the way the model operates. The model still makes predictions one hour into the future based on a single input time step. Here, the `time` axis acts like the `batch` axis: each prediction is made independently with no interaction between time steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8jNR5uuJ5Zp"
      },
      "outputs": [],
      "source": [
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "wide_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAnj7CFZkuYv"
      },
      "source": [
        "이 확장된 창은 어떠한 코드 변경 없이 동일한 `baseline` 모델에 직접 전달할 수 있습니다. 이는 입력과 레이블이 동일한 수의 타임스텝을 가지며 기준이 입력을 출력으로 전달하기 때문에 가능합니다.\n",
        "\n",
        "![One prediction 1h into the future, ever hour.](images/last_window.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGKdvdg087qs"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', baseline(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqQHX1K0JW-"
      },
      "source": [
        "By plotting the baseline model's predictions, notice that it is simply the labels shifted right by one hour:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQyAPVLgWTOZ"
      },
      "outputs": [],
      "source": [
        "wide_window.plot(baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e93TLUhfAVg2"
      },
      "source": [
        "In the above plots of three examples the single step model is run over the course of 24 hours. This deserves some explanation:\n",
        "\n",
        "- The blue `Inputs` line shows the input temperature at each time step. The model receives all features, this plot only shows the temperature.\n",
        "- The green `Labels` dots show the target prediction value. These dots are shown at the prediction time, not the input time. That is why the range of labels is shifted 1 step relative to the inputs.\n",
        "- The orange `Predictions` crosses are the model's prediction's for each output time step. If the model were predicting perfectly the predictions would land directly on the `Labels`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4aOJScj52Yu"
      },
      "source": [
        "### 선형 모델\n",
        "\n",
        "이 작업에 적용할 수 있는 가장 간단한 **훈련 가능한** 모델은 입력과 출력 사이에 선형 변환을 삽입하는 것입니다. 이 경우 타임스텝의 출력은 해당 스텝에만 의존합니다.\n",
        "\n",
        "![A single step prediction](images/narrow_window.png)\n",
        "\n",
        "A `tf.keras.layers.Dense` layer with no `activation` set is a linear model. The layer only transforms the last axis of the data from `(batch, time, inputs)` to `(batch, time, units)`; it is applied independently to every item across the `batch` and `time` axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6341OXuQ5xA9"
      },
      "outputs": [],
      "source": [
        "linear = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwaOM8RucUSn"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', single_step_window.example[0].shape)\n",
        "print('Output shape:', linear(single_step_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMZTYIj3bYLg"
      },
      "source": [
        "이 튜토리얼은 많은 모델을 훈련하므로 훈련 절차를 하나의 함수 패키지로 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbCL6VIrk-Gt"
      },
      "outputs": [],
      "source": [
        "MAX_EPOCHS = 20\n",
        "\n",
        "def compile_and_fit(model, window, patience=2):\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=patience,\n",
        "                                                    mode='min')\n",
        "\n",
        "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
        "                      validation_data=window.val,\n",
        "                      callbacks=[early_stopping])\n",
        "  return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OobVjM-schwj"
      },
      "source": [
        "모델을 훈련하고 성능을 평가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9agbz2qB9bLS"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(linear, single_step_window)\n",
        "\n",
        "val_performance['Linear'] = linear.evaluate(single_step_window.val)\n",
        "performance['Linear'] = linear.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U9XukYh8beN"
      },
      "source": [
        "`baseline` 모델과 마찬가지로 선형 모델은 넓은 범위의 배치에서 호출할 수 있습니다. 이러한 방식으로 모델은 연속적인 타임스텝에 대해 일련의 독립적인 예측을 수행합니다. `time` 축은 다른 `batch` 축처럼 작동합니다. 각 타임스텝에서 예측 사이에 상호 작용은 없습니다.\n",
        "\n",
        "![A single step prediction](images/wide_window.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9UVM5Sw9KQN"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', baseline(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-CGj85oKaOG"
      },
      "source": [
        "다음은 `wide_widow`에 대한 예제 예측을 플롯한 내용입니다. 많은 경우 예측이 단순히 입력 온도를 반환하는 것보다는 분명히 더 낮지만 몇 가지 경우에는 더 나쁘다는 사실에 주목하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCC8VVo-OvwV"
      },
      "outputs": [],
      "source": [
        "wide_window.plot(linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is51vU8EMl6c"
      },
      "source": [
        "One advantage to linear models is that they're relatively simple to  interpret. You can pull out the layer's weights and visualize the weight assigned to each input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4uCTbsmK8VI"
      },
      "outputs": [],
      "source": [
        "plt.bar(x = range(len(train_df.columns)),\n",
        "        height=linear.layers[0].kernel[:,0].numpy())\n",
        "axis = plt.gca()\n",
        "axis.set_xticks(range(len(train_df.columns)))\n",
        "_ = axis.set_xticklabels(train_df.columns, rotation=90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ylng7215boIY"
      },
      "source": [
        "때로 모델은 입력 `T (degC)`에 가장 많은 가중치를 두지 않습니다. 이것은 무작위 초기화의 위험 중 하나입니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W18e6da1cNbw"
      },
      "source": [
        "### 밀집\n",
        "\n",
        "실제로 여러 타임스텝에서 동작하는 모델을 적용하기 전에 더 깊고 강력한 단일 입력 스텝 모델의 성능을 확인하는 것이 좋습니다.\n",
        "\n",
        "다음 모델은 입력과 출력 사이에 몇 개의 `Dense` 레이어를 쌓는다는 점을 제외하면 `linear` 모델과 유사합니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z86WkYp7cNAD"
      },
      "outputs": [],
      "source": [
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(dense, single_step_window)\n",
        "\n",
        "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
        "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5dv_whJdswH"
      },
      "source": [
        "### 다중 스텝 밀집\n",
        "\n",
        "단일 타임스텝 모델에는 입력의 현재 값에 대한 컨텍스트가 없습니다. 시간에 따라 입력 특성이 어떻게 변하는지 볼 수 없습니다. 이 문제를 해결하려면 모델이 예측을 수행할 때 여러 타임스텝에 액세스해야 합니다.\n",
        "\n",
        "![Three time steps are used for each prediction.](images/conv_window.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zac-ti8agbJ7"
      },
      "source": [
        "`baseline` , `linear` 및 `dense` 모델은 각 타임스텝을 독립적으로 처리했습니다. 여기서 모델은 단일 출력을 생성하기 위해 여러 타임스텝을 입력으로 사용합니다.\n",
        "\n",
        "Create a `WindowGenerator` that will produce batches of three-hour inputs and one-hour labels:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtN4BwZ37niR"
      },
      "source": [
        "`Window`의 `shift` 매개변수는 두 창의 끝에 상대적입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBh0j5djUKY2"
      },
      "outputs": [],
      "source": [
        "CONV_WIDTH = 3\n",
        "conv_window = WindowGenerator(\n",
        "    input_width=CONV_WIDTH,\n",
        "    label_width=1,\n",
        "    shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "conv_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCQ5gvs68Xkd"
      },
      "outputs": [],
      "source": [
        "conv_window.plot()\n",
        "plt.title(\"Given 3 hours of inputs, predict 1 hour into the future.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We0HdMxKeqB_"
      },
      "source": [
        "You could train a `dense` model on a multiple-input-step window by adding a `tf.keras.layers.Flatten` as the first layer of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNQnUOkOnC1G"
      },
      "outputs": [],
      "source": [
        "multi_step_dense = tf.keras.Sequential([\n",
        "    # Shape: (time, features) => (time*features)\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "    # Add back the time dimension.\n",
        "    # Shape: (outputs) => (1, outputs)\n",
        "    tf.keras.layers.Reshape([1, -1]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cayD74luo4Vq"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', conv_window.example[0].shape)\n",
        "print('Output shape:', multi_step_dense(conv_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu91yEbRo9-J"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(multi_step_dense, conv_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.val)\n",
        "performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnqdXYT6pkEh"
      },
      "outputs": [],
      "source": [
        "conv_window.plot(multi_step_dense)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWfrsP8mq8lV"
      },
      "source": [
        "이 접근법의 주된 단점은 결과적인 모델이 정확히 이 형상의 입력 창에서만 실행될 수 있다는 것입니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-q6tz5Yq8Jk"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "try:\n",
        "  print('Output shape:', multi_step_dense(wide_window.example[0]).shape)\n",
        "except Exception as e:\n",
        "  print(f'\\n{type(e).__name__}:{e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvvajm3ip_8V"
      },
      "source": [
        "다음 섹션의 컨볼루셔널 모델은 이 문제를 해결합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrpU6gwSJome"
      },
      "source": [
        "### 컨볼루션 신경망\n",
        "\n",
        "A convolution layer (`tf.keras.layers.Conv1D`) also takes multiple time steps as input to each prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdLBwoaHmsWb"
      },
      "source": [
        "다음은 컨볼루션으로 다시 작성한 `multi_step_dense`와 **동일한** 모델입니다.\n",
        "\n",
        "다음 변경 사항에 주목하세요.\n",
        "\n",
        "- The `tf.keras.layers.Flatten` and the first `tf.keras.layers.Dense` are replaced by a `tf.keras.layers.Conv1D`.\n",
        "- The `tf.keras.layers.Reshape` is no longer necessary since the convolution keeps the time axis in its output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5azaMBj4ac9t"
      },
      "outputs": [],
      "source": [
        "conv_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=32,\n",
        "                           kernel_size=(CONV_WIDTH,),\n",
        "                           activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftaH6B5ECRiK"
      },
      "source": [
        "Run it on an example batch to check that the model produces outputs with the expected shape:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YNgt1-e98lH"
      },
      "outputs": [],
      "source": [
        "print(\"Conv model on `conv_window`\")\n",
        "print('Input shape:', conv_window.example[0].shape)\n",
        "print('Output shape:', conv_model(conv_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m4kC-jGCY3x"
      },
      "source": [
        "`conv_window`에서 훈련하고 평가하면 `multi_step_dense` 모델과 유사한 성능을 제공해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDVWdm4paUW7"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(conv_model, conv_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Conv'] = conv_model.evaluate(conv_window.val)\n",
        "performance['Conv'] = conv_model.evaluate(conv_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYRipDeXs0Kr"
      },
      "source": [
        "이 `conv_model`과 `multi_step_dense` 모델의 차이점은 `conv_model`은 모든 길이의 입력에서 실행될 수 있다는 것입니다. 컨볼루셔널 레이어는 입력의 슬라이딩 창에 적용됩니다.\n",
        "\n",
        "![시퀀스에서 컨볼루션 모델 실행](images/wide_conv_window.png)\n",
        "\n",
        "더 넓은 입력에서 실행하면 더 넓은 출력이 생성됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoqccxx9r5jF"
      },
      "outputs": [],
      "source": [
        "print(\"Wide window\")\n",
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Labels shape:', wide_window.example[1].shape)\n",
        "print('Output shape:', conv_model(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_WGxtLIHhRF"
      },
      "source": [
        "출력은 입력보다 짧습니다. 훈련 또는 플롯 작업을 수행하려면 레이블과 예상의 길이가 동일해야 합니다. 따라서 레이블과 예측 길이가 일치하도록 몇 개의 추가 입력 타임스텝으로 넓은 창을 생성하는 `WindowGenerator`를 빌드합니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VPvJ_VwTc0f"
      },
      "outputs": [],
      "source": [
        "LABEL_WIDTH = 24\n",
        "INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\n",
        "wide_conv_window = WindowGenerator(\n",
        "    input_width=INPUT_WIDTH,\n",
        "    label_width=LABEL_WIDTH,\n",
        "    shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "wide_conv_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtqlWYXeKXej"
      },
      "outputs": [],
      "source": [
        "print(\"Wide conv window\")\n",
        "print('Input shape:', wide_conv_window.example[0].shape)\n",
        "print('Labels shape:', wide_conv_window.example[1].shape)\n",
        "print('Output shape:', conv_model(wide_conv_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzxbbS56cSBV"
      },
      "source": [
        "Now, you can plot the model's predictions on a wider window. Note the 3 input time steps before the first prediction. Every prediction here is based on the 3 preceding time steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gR7VyL45UuEe"
      },
      "outputs": [],
      "source": [
        "wide_conv_window.plot(conv_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "### 순환 신경망\n",
        "\n",
        "Recurrent Neural Network(RNN)는 시계열 데이터에 적합한 신경망 유형입니다. RNN은 시계열을 단계별로 처리하여 타임스텝 사이에서 내부 상태를 유지합니다.\n",
        "\n",
        "You can learn more in the [Text generation with an RNN](https://www.tensorflow.org/text/tutorials/text_generation) tutorial and the [Recurrent Neural Networks (RNN) with Keras](https://www.tensorflow.org/guide/keras/rnn) guide.\n",
        "\n",
        "In this tutorial, you will use an RNN layer called Long Short-Term Memory (`tf.keras.layers.LSTM`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfQbHSMb1ATa"
      },
      "source": [
        "An important constructor argument for all Keras RNN layers, such as `tf.keras.layers.LSTM`, is the `return_sequences` argument. This setting can configure the layer in one of two ways:\n",
        "\n",
        "1. 기본값인 `False`인 경우 레이어는 최종 타임스텝의 출력만 반환하여 단일 예측을 수행하기 전에 모델이 내부 상태를 준비할 시간을 줍니다.\n",
        "\n",
        "![lstm 워밍업 및 단일 예측](images/lstm_1_window.png)\n",
        "\n",
        "1. If `True`, the layer returns an output for each input. This is useful for:\n",
        "    - RNN 레이어 스태킹\n",
        "    - 여러 타임스텝에서 동시에 모델 훈련\n",
        "\n",
        "![모든 타임스텝 후에 예측하는 lstm](images/lstm_many_window.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXKLCJy8nWNU"
      },
      "outputs": [],
      "source": [
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F124B00KZcLC"
      },
      "source": [
        "With `return_sequences=True`, the model can be trained on 24 hours of data at a time.\n",
        "\n",
        "Note: This will give a pessimistic view of the model's performance. On the first time step, the model has no access to previous steps and, therefore, can't do any better than the simple `linear` and `dense` models shown earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZEROCQVYV6q"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', lstm_model(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvdWRl1e9WJl"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(lstm_model, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['LSTM'] = lstm_model.evaluate(wide_window.val)\n",
        "performance['LSTM'] = lstm_model.evaluate(wide_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwAOWCVgB26e"
      },
      "outputs": [],
      "source": [
        "wide_window.plot(lstm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYglOCKehi8F"
      },
      "source": [
        "### 성능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pCk0_rwhi8H"
      },
      "source": [
        "With this dataset typically each of the models does slightly better than the one before it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjEkt488hi8I"
      },
      "outputs": [],
      "source": [
        "x = np.arange(len(performance))\n",
        "width = 0.3\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in performance.values()]\n",
        "\n",
        "plt.ylabel('mean_absolute_error [T (degC), normalized]')\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=performance.keys(),\n",
        "           rotation=45)\n",
        "_ = plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBMCpsdphi8L"
      },
      "outputs": [],
      "source": [
        "for name, value in performance.items():\n",
        "  print(f'{name:12s}: {value[1]:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5rUJ_2YMWzG"
      },
      "source": [
        "### 다중 출력 모델\n",
        "\n",
        "지금까지 모델은 모두 단일 타임스텝에 대해 단일 출력 특성 `T (degC)`를 예측했습니다.\n",
        "\n",
        "All of these models can be converted to predict multiple features just by changing the number of units in the output layer and adjusting the training windows to include all features in the `labels` (`example_labels`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gk0Z91xjOwv"
      },
      "outputs": [],
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    # `WindowGenerator` returns all features as labels if you \n",
        "    # don't set the `label_columns` argument.\n",
        "    input_width=1, label_width=1, shift=1)\n",
        "\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1)\n",
        "\n",
        "for example_inputs, example_labels in wide_window.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmcjHfDskX1N"
      },
      "source": [
        "레이블의 `features` 축은 이제 1이 아닌 입력과 동일한 깊이를 갖습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k7S5IHNhSNF"
      },
      "source": [
        "#### 기준\n",
        "\n",
        "The same baseline model (`Baseline`) can be used here, but this time repeating all features instead of selecting a specific `label_index`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqqB9W-pjr5i"
      },
      "outputs": [],
      "source": [
        "baseline = Baseline()\n",
        "baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                 metrics=[tf.metrics.MeanAbsoluteError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltQdgaqQjQWu"
      },
      "outputs": [],
      "source": [
        "val_performance = {}\n",
        "performance = {}\n",
        "val_performance['Baseline'] = baseline.evaluate(wide_window.val)\n",
        "performance['Baseline'] = baseline.evaluate(wide_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfbCrf5q3P6n"
      },
      "source": [
        "#### 밀집"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdpzH1dYjdIN"
      },
      "outputs": [],
      "source": [
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uHuU9Cd3PTo"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(dense, single_step_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
        "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsc9pur_mHsx"
      },
      "source": [
        "#### RNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QbGLMyomXaz"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1)\n",
        "\n",
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(lstm_model, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['LSTM'] = lstm_model.evaluate( wide_window.val)\n",
        "performance['LSTM'] = lstm_model.evaluate( wide_window.test, verbose=0)\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwhY2f_Nn0_K"
      },
      "source": [
        "<a id=\"residual\"></a>\n",
        "\n",
        "#### 고급: 잔여 연결\n",
        "\n",
        "이전의 `Baseline` 모델은 시퀀스가 타임스텝 사이에서 크게 변하지 않는다는 사실을 이용했습니다. 지금까지 이 튜토리얼에서 훈련한 모든 모델은 무작위로 초기화된 다음, 출력이 이전 타임스텝에서 약간 변경된다는 사실을 학습해야 했습니다.\n",
        "\n",
        "신중한 초기화로 이 문제를 해결할 수 있지만 모델 구조로 빌드하는 것이 더 간단합니다.\n",
        "\n",
        "It's common in time series analysis to build models that instead of predicting the next value, predict how the value will change in the next time step. Similarly, <a href=\"https://arxiv.org/abs/1512.03385\" class=\"external\">residual networks</a>—or ResNets—in deep learning refer to architectures where each layer adds to the model's accumulating result.\n",
        "\n",
        "이것은 변화가 작아야 한다는 사실을 이용하는 방법입니다.\n",
        "\n",
        "![A model with a residual connection](images/residual.png)\n",
        "\n",
        "기본적으로, `Baseline`과 일치하도록 모델을 초기화합니다. 그러면 이 작업에서 약간 더 나은 성능으로 모델이 더 빨리 수렴시키는 데 도움이 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP58A_ORx0kM"
      },
      "source": [
        "이 접근 방식은 이 튜토리얼에서 설명하는 모든 모델과 연계하여 사용할 수 있습니다.\n",
        "\n",
        "여기서는 LSTM 모델에 적용합니다. `tf.initializers.zeros`를 사용하여 초기 예측하는 변경이 작고 잔류 연결을 압도하지 않도록 한다는 점에 유의하세요. `zeros`가 마지막 레이어에서만 사용되기 때문에 여기에서 그래디언트에 대한 대칭 파괴 문제는 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YlfnDQC22TQ"
      },
      "outputs": [],
      "source": [
        "class ResidualWrapper(tf.keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "\n",
        "  def call(self, inputs, *args, **kwargs):\n",
        "    delta = self.model(inputs, *args, **kwargs)\n",
        "\n",
        "    # The prediction for each time step is the input\n",
        "    # from the previous time step plus the delta\n",
        "    # calculated by the model.\n",
        "    return inputs + delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNeH02pspc9B"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "residual_lstm = ResidualWrapper(\n",
        "    tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    tf.keras.layers.Dense(\n",
        "        num_features,\n",
        "        # The predicted deltas should start small.\n",
        "        # Therefore, initialize the output layer with zeros.\n",
        "        kernel_initializer=tf.initializers.zeros())\n",
        "]))\n",
        "\n",
        "history = compile_and_fit(residual_lstm, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.val)\n",
        "performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.test, verbose=0)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I42Er9Du6co1"
      },
      "source": [
        "#### 성능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZxR38P_6pUi"
      },
      "source": [
        "다음은 이러한 다중 출력 모델의 전반적인 성능입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XgTK9tnr7rc"
      },
      "outputs": [],
      "source": [
        "x = np.arange(len(performance))\n",
        "width = 0.3\n",
        "\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in performance.values()]\n",
        "\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=performance.keys(),\n",
        "           rotation=45)\n",
        "plt.ylabel('MAE (average over all outputs)')\n",
        "_ = plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URz3ajCc6kBj"
      },
      "outputs": [],
      "source": [
        "for name, value in performance.items():\n",
        "  print(f'{name:15s}: {value[1]:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vt2MJhNxwPU"
      },
      "source": [
        "위의 성능은 모든 모델 출력에 대한 평균입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYokb7Om2YbK"
      },
      "source": [
        "## 다중 스텝 모델\n",
        "\n",
        "Both the single-output and multiple-output models in the previous sections made **single time step predictions**, one hour into the future.\n",
        "\n",
        "이 섹션에서는 이러한 모델을 확장하여 **다중 타임스텝 예측**을 수행하는 방법을 살펴봅니다.\n",
        "\n",
        "다중 스텝 예측에서 모델은 일정 범위의 미래 값을 예측하는 방법을 학습해야 합니다. 따라서 한 미래 시점만 예측하는 단일 스텝 모델과 달리 다중 스텝 모델은 미래 값의 시퀀스를 예측합니다.\n",
        "\n",
        "대략적으로 두 가지 접근 방식이 있습니다.\n",
        "\n",
        "1. 전체 시계열이 한 번에 예측되는 싱글샷 예측\n",
        "2. 모델이 단일 스텝 예측만 수행하고 출력이 입력으로 피드백되는 자기 회귀적 예측\n",
        "\n",
        "이 섹션에서는 모든 모델이 **모든 출력 타임스텝에 걸쳐 모든 특성**을 예측합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFsDAwVt4_rq"
      },
      "source": [
        "For the multi-step model, the training data again consists of hourly samples. However, here, the models will learn to predict 24 hours into the future, given 24 hours of the past.\n",
        "\n",
        "다음은 데이터세트로부터 이러한 조각을 생성하는 `Window` 객체입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cFYtsz6XiGw"
      },
      "outputs": [],
      "source": [
        "OUT_STEPS = 24\n",
        "multi_window = WindowGenerator(input_width=24,\n",
        "                               label_width=OUT_STEPS,\n",
        "                               shift=OUT_STEPS)\n",
        "\n",
        "multi_window.plot()\n",
        "multi_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lg8SInh9Jzd"
      },
      "source": [
        "### 기준"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axwpoWYOApJL"
      },
      "source": [
        "이 작업의 간단한 기준은 필요한 출력 타임스텝 수에 대해 마지막 입력 타임스텝을 반복하는 것입니다.\n",
        "\n",
        "![각 출력 단계에 대해 마지막 입력 반복](images/multistep_last.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5iaHSaJ9Rxv"
      },
      "outputs": [],
      "source": [
        "class MultiStepLastBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])\n",
        "\n",
        "last_baseline = MultiStepLastBaseline()\n",
        "last_baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                      metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "multi_val_performance = {}\n",
        "multi_performance = {}\n",
        "\n",
        "multi_val_performance['Last'] = last_baseline.evaluate(multi_window.val)\n",
        "multi_performance['Last'] = last_baseline.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(last_baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvHZ93ObAfMA"
      },
      "source": [
        "Since this task is to predict 24 hours into the future, given 24 hours of the past, another simple approach is to repeat the previous day, assuming tomorrow will be similar:\n",
        "\n",
        "![Repeat the previous day](images/multistep_repeat.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8Y1uMhGwIRs"
      },
      "outputs": [],
      "source": [
        "class RepeatBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return inputs\n",
        "\n",
        "repeat_baseline = RepeatBaseline()\n",
        "repeat_baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                        metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "multi_val_performance['Repeat'] = repeat_baseline.evaluate(multi_window.val)\n",
        "multi_performance['Repeat'] = repeat_baseline.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(repeat_baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbndS-ct9C2Q"
      },
      "source": [
        "### 싱글샷 모델\n",
        "\n",
        "One high-level approach to this problem is to use a \"single-shot\" model, where the model makes the entire sequence prediction in a single step.\n",
        "\n",
        "This can be implemented efficiently as a `tf.keras.layers.Dense` with `OUT_STEPS*features` output units. The model just needs to reshape that output to the required `(OUTPUT_STEPS, features)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCKS4m1VKrDQ"
      },
      "source": [
        "#### 선형\n",
        "\n",
        "마지막 입력 타임스텝을 기반으로 하는 단순한 선형 모델은 기준 모델보다 성능이 더 좋지만 강력하지 못합니다. 이 모델은 선형 프로젝션을 이용해 단일 입력 타임스텝으로부터 `OUTPUT_STEPS` 타임스텝을 예측해야 합니다. 주로 하루 중 시간과 연중 시간을 기반으로 하는 행동의 저차원 조각만 캡처할 수 있습니다.\n",
        "\n",
        "![마지막 타임스텝에서 모든 타임스텝 예측](images/multistep_dense.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfRz_WVhIQcd"
      },
      "outputs": [],
      "source": [
        "multi_linear_model = tf.keras.Sequential([\n",
        "    # Take the last time-step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_linear_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "multi_val_performance['Linear'] = multi_linear_model.evaluate(multi_window.val)\n",
        "multi_performance['Linear'] = multi_linear_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_linear_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi2TMHk2IRrh"
      },
      "source": [
        "#### 밀집\n",
        "\n",
        "Adding a `tf.keras.layers.Dense` between the input and output gives the linear model more power, but is still only based on a single input time step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jezm-BKaGj91"
      },
      "outputs": [],
      "source": [
        "multi_dense_model = tf.keras.Sequential([\n",
        "    # Take the last time step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, dense_units]\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Shape => [batch, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_dense_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "multi_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val)\n",
        "multi_performance['Dense'] = multi_dense_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_dense_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icsBAjCzMaMl"
      },
      "source": [
        "#### CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34lCZrWYNBwd"
      },
      "source": [
        "컨볼루션 모델은 고정 너비 기록을 기반으로 예측을 수행하므로 시간에 따라 상황이 어떻게 변하는지 볼 수 있어 밀집 모델보다 성능을 높일 수 있습니다.\n",
        "\n",
        "![컨볼루션 모델은 시간이 지남에 따라 상황이 어떻게 변하는지 확인합니다](images/multistep_conv.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xJoIP6PMWMI"
      },
      "outputs": [],
      "source": [
        "CONV_WIDTH = 3\n",
        "multi_conv_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
        "    # Shape => [batch, 1, conv_units]\n",
        "    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n",
        "    # Shape => [batch, 1,  out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_conv_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val)\n",
        "multi_performance['Conv'] = multi_conv_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_conv_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weBjeZAFJOP4"
      },
      "source": [
        "#### RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8022xOKxOO92"
      },
      "source": [
        "A recurrent model can learn to use a long history of inputs, if it's relevant to the predictions the model is making. Here the model will accumulate internal state for 24 hours, before making a single prediction for the next 24 hours.\n",
        "\n",
        "In this single-shot format, the LSTM only needs to produce an output at the last time step, so set `return_sequences=False` in `tf.keras.layers.LSTM`.\n",
        "\n",
        "![lstm은 입력 창에 대한 상태를 누적하고 다음 24시간 동안 단일 예측을 수행합니다](https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tutorials/structured_data/images/multistep_lstm.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf1ks6RTzF64"
      },
      "outputs": [],
      "source": [
        "multi_lstm_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, lstm_units].\n",
        "    # Adding more `lstm_units` just overfits more quickly.\n",
        "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
        "    # Shape => [batch, out_steps*features].\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features].\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_lstm_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\n",
        "multi_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_lstm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5n-1cDW12Vo"
      },
      "source": [
        "### 고급: 자기 회귀 모델\n",
        "\n",
        "위의 모델은 모두 한 번에 전체 출력 시퀀스를 예측합니다.\n",
        "\n",
        "경우에 따라 모델이 이 예측을 여러 타임스텝으로 분해하는 것이 도움이 될 수 있습니다. 그러면 이전의 <a href=\"https://arxiv.org/abs/1308.0850\" class=\"external\">RNN(Recurrent Neural Networks)을 이용한 시퀀스 생성</a>에서와 같이 각 모델의 출력을 각 스텝에서 자체 피드백할 수 있어 이전 예측을 조건부로 예측을 수행할 수 있습니다.\n",
        "\n",
        "이 형태의 모델이 갖는 한 가지 분명한 장점은 다양한 길이의 출력을 생성하도록 설정할 수 있다는 것입니다.\n",
        "\n",
        "이 튜토리얼의 전반부에서 훈련한 단일 스텝 다중 출력 모델 중 하나를 가져와 자기 회귀 피드백 루프에서 실행할 수 있지만 여기서는 이를 수행하도록 명시적으로 훈련된 모델을 빌드하는 데 중점을 둘 것입니다.\n",
        "\n",
        "![모델의 출력을 입력으로 피드백](images/multistep_autoregressive.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKRreBbULRXY"
      },
      "source": [
        "#### RNN\n",
        "\n",
        "이 튜토리얼에서는 자기 회귀 RNN 모델만 빌드하지만 이 패턴은 단일 타임스텝을 출력하도록 설계된 모든 모델에 적용할 수 있습니다.\n",
        "\n",
        "The model will have the same basic form as the single-step LSTM models from earlier: a `tf.keras.layers.LSTM` layer followed by a `tf.keras.layers.Dense` layer that converts the `LSTM` layer's outputs to model predictions.\n",
        "\n",
        "A `tf.keras.layers.LSTM` is a `tf.keras.layers.LSTMCell` wrapped in the higher level `tf.keras.layers.RNN` that manages the state and sequence results for you (Check out the [Recurrent Neural Networks (RNN) with Keras](https://www.tensorflow.org/guide/keras/rnn) guide for details).\n",
        "\n",
        "In this case, the model has to manually manage the inputs for each step, so it uses `tf.keras.layers.LSTMCell` directly for the lower level, single time step interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5tz3Nu0R5JG"
      },
      "outputs": [],
      "source": [
        "class FeedBack(tf.keras.Model):\n",
        "  def __init__(self, units, out_steps):\n",
        "    super().__init__()\n",
        "    self.out_steps = out_steps\n",
        "    self.units = units\n",
        "    self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
        "    # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
        "    self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OXVM9G1U7xR"
      },
      "outputs": [],
      "source": [
        "feedback_model = FeedBack(units=32, out_steps=OUT_STEPS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph5uFSfTUNho"
      },
      "source": [
        "The first method this model needs is a `warmup` method to initialize its internal state based on the inputs. Once trained, this state will capture the relevant parts of the input history. This is equivalent to the single-step `LSTM` model from earlier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM2K_LLdRjDZ"
      },
      "outputs": [],
      "source": [
        "def warmup(self, inputs):\n",
        "  # inputs.shape => (batch, time, features)\n",
        "  # x.shape => (batch, lstm_units)\n",
        "  x, *state = self.lstm_rnn(inputs)\n",
        "\n",
        "  # predictions.shape => (batch, features)\n",
        "  prediction = self.dense(x)\n",
        "  return prediction, state\n",
        "\n",
        "FeedBack.warmup = warmup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JkaSYaZ9eB7"
      },
      "source": [
        "This method returns a single time-step prediction and the internal state of the `LSTM`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9Fz6NTKXXwU"
      },
      "outputs": [],
      "source": [
        "prediction, state = feedback_model.warmup(multi_window.example[0])\n",
        "prediction.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_ZdvPjdX3y3"
      },
      "source": [
        "`RNN`의 상태 및 초기 예측을 사용하여 이제 이전의 각 스텝에서 수행한 예측을 입력으로 제공하여 모델을 계속 반복할 수 있습니다.\n",
        "\n",
        "The simplest approach for collecting the output predictions is to use a Python list and a `tf.stack` after the loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yotTad3nZXQU"
      },
      "source": [
        "Note: Stacking a Python list like this only works with eager-execution, using `Model.compile(..., run_eagerly=True)` for training, or with a fixed length output. For a dynamic output length, you would need to use a `tf.TensorArray` instead of a Python list, and `tf.range` instead of the Python `range`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1GRDu3mZtr9"
      },
      "outputs": [],
      "source": [
        "def call(self, inputs, training=None):\n",
        "  # Use a TensorArray to capture dynamically unrolled outputs.\n",
        "  predictions = []\n",
        "  # Initialize the LSTM state.\n",
        "  prediction, state = self.warmup(inputs)\n",
        "\n",
        "  # Insert the first prediction.\n",
        "  predictions.append(prediction)\n",
        "\n",
        "  # Run the rest of the prediction steps.\n",
        "  for n in range(1, self.out_steps):\n",
        "    # Use the last prediction as input.\n",
        "    x = prediction\n",
        "    # Execute one lstm step.\n",
        "    x, state = self.lstm_cell(x, states=state,\n",
        "                              training=training)\n",
        "    # Convert the lstm output to a prediction.\n",
        "    prediction = self.dense(x)\n",
        "    # Add the prediction to the output.\n",
        "    predictions.append(prediction)\n",
        "\n",
        "  # predictions.shape => (time, batch, features)\n",
        "  predictions = tf.stack(predictions)\n",
        "  # predictions.shape => (batch, time, features)\n",
        "  predictions = tf.transpose(predictions, [1, 0, 2])\n",
        "  return predictions\n",
        "\n",
        "FeedBack.call = call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubop-YWp15XW"
      },
      "source": [
        "예제 입력에서 이 모델을 테스트 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xja83zEYaM2D"
      },
      "outputs": [],
      "source": [
        "print('Output shape (batch, time, features): ', feedback_model(multi_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMs0rYB8be9M"
      },
      "source": [
        "Now, train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBRVG2hnNyrO"
      },
      "outputs": [],
      "source": [
        "history = compile_and_fit(feedback_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['AR LSTM'] = feedback_model.evaluate(multi_window.val)\n",
        "multi_performance['AR LSTM'] = feedback_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(feedback_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGjcJsAQJUkI"
      },
      "source": [
        "### 성능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sODAwr2ndtDB"
      },
      "source": [
        "There are clearly diminishing returns as a function of model complexity on this problem:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZwWBA8S6B3L"
      },
      "outputs": [],
      "source": [
        "x = np.arange(len(multi_performance))\n",
        "width = 0.3\n",
        "\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in multi_val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in multi_performance.values()]\n",
        "\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=multi_performance.keys(),\n",
        "           rotation=45)\n",
        "plt.ylabel(f'MAE (average over all times and outputs)')\n",
        "_ = plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq3hUsedCEmJ"
      },
      "source": [
        "The metrics for the multi-output models in the first half of this tutorial show the performance averaged across all output features. These performances are similar but also averaged across output time steps. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKq3eAIvH4Db"
      },
      "outputs": [],
      "source": [
        "for name, value in multi_performance.items():\n",
        "  print(f'{name:8s}: {value[1]:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpBFwfnaHP23"
      },
      "source": [
        "밀집 모델에서 컨볼루션 및 반복 모델로 이동하여 얻은 이득은 몇 퍼센트(있다고 하더라도)에 불과하며 자기 회귀 모델의 성능은 분명히 더 나빴습니다. 따라서 이러한 더 복잡한 접근 방법은 **이** 문제에서는 가치가 없을 수도 있지만 시도해 보기 전에는 알 수 있는 방법이 없었으며 이러한 모델은 **다른 특정** 문제에 도움이 될 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOzaIRYBhqwg"
      },
      "source": [
        "## 다음 단계\n",
        "\n",
        "이 튜토리얼에서는 TensorFlow를 사용한 시계열 예측에 대해 간단히 소개했습니다.\n",
        "\n",
        "To learn more, refer to:\n",
        "\n",
        "- Chapter 15 of <a href=\"https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/\" class=\"external\">Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow</a>, 2nd Edition.\n",
        "- [Python을 이용한 딥러닝](https://www.manning.com/books/deep-learning-with-python) 챕터 6\n",
        "- Lesson 8 of <a href=\"https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187\" class=\"external\">Udacity's intro to TensorFlow for deep learning</a>, including the <a href=\"https://github.com/tensorflow/examples/tree/master/courses/udacity_intro_to_tensorflow_for_deep_learning\" class=\"external\">exercise notebooks</a>.\n",
        "\n",
        "Also, remember that you can implement any <a href=\"https://otexts.com/fpp2/index.html\" class=\"external\">classical time series model</a> in TensorFlow—this tutorial just focuses on TensorFlow's built-in functionality.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "time_series.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
