{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEL3NlTTDlSX"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FlUw7tSKbtg4"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# TF2 마이그레이션된 교육 파이프라인 디버그\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/migration_debugging\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/guide/migrate/migration_debugging.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/guide/migrate/migration_debugging.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/guide/migrate/migration_debugging.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTwPu-w6M5sz"
      },
      "source": [
        "이 노트북은 TF2로 마이그레이션할 때 훈련 파이프라인을 디버그하는 방법을 보여줍니다. 다음 구성 요소로 구성됩니다.\n",
        "\n",
        "1. 교육 파이프라인 디버깅을 위한 제안 단계 및 코드 샘플\n",
        "2. 디버깅 도구\n",
        "3. 기타 관련 리소스\n",
        "\n",
        "한 가지 가정은 비교를 위해 TF1.x 코드와 훈련된 모델이 있고 유사한 유효성 검사 정확도를 달성하는 TF2 모델을 구축하려는 것입니다.\n",
        "\n",
        "이 노트북은 훈련/추론 속도 또는 메모리 사용에 대한 디버깅 성능 문제를 **다루지 않습니다.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKm9R4CtOAP3"
      },
      "source": [
        "## 디버깅 워크플로\n",
        "\n",
        "다음은 TF2 훈련 파이프라인을 디버깅하기 위한 일반적인 워크플로입니다. 이 단계를 순서대로 따를 필요는 없습니다. 중간 단계에서 모델을 테스트하고 디버깅 범위를 좁히는 이진 검색 접근 방식을 사용할 수도 있습니다.\n",
        "\n",
        "1. 컴파일 및 런타임 오류 수정\n",
        "\n",
        "2. 단일 정방향 패스 검증(별도 [가이드](./validate_correctness.ipynb) )\n",
        "\n",
        "    NS. 단일 CPU 장치에서\n",
        "\n",
        "    - 변수가 한 번만 생성되었는지 확인\n",
        "    - 변수 개수, 이름 및 모양이 일치하는지 확인\n",
        "    - 모든 변수 재설정, 모든 임의성이 비활성화된 상태에서 수치적 동등성 확인\n",
        "    - 난수 생성 정렬, 추론에서 수치적 동등성 확인\n",
        "    - (선택 사항) 체크포인트가 제대로 로드되고 TF1.x/TF2 모델이 동일한 출력을 생성하는지 확인합니다.\n",
        "\n",
        "    NS. 단일 GPU/TPU 장치에서\n",
        "\n",
        "    씨. 다중 장치 전략으로\n",
        "\n",
        "3. 몇 단계에 대한 모델 훈련 수치 동등성 검증(아래에서 코드 샘플 사용 가능)\n",
        "\n",
        "    NS. 단일 CPU 장치에서 작고 고정된 데이터를 사용하는 단일 훈련 단계 검증. 특히 다음 구성 요소에 대한 수치 동등성을 확인하십시오.\n",
        "\n",
        "    - 손실 계산\n",
        "    - 측정항목\n",
        "    - 학습률\n",
        "    - 기울기 계산 및 업데이트\n",
        "\n",
        "    NS. 단일 CPU 장치에 고정 데이터가 있는 모멘텀과 같은 옵티마이저 동작을 확인하기 위해 3개 이상의 단계를 교육한 후 통계를 확인합니다.\n",
        "\n",
        "    씨. 단일 GPU/TPU 장치에서\n",
        "\n",
        "    NS. 다중 장치 전략 사용(하단의 [MultiProcessRunner 소개 확인)](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/distribute/multi_process_runner.py#L108)\n",
        "\n",
        "4. 실제 데이터 세트에 대한 종단 간 커버리지 테스트\n",
        "\n",
        "    NS. TensorBoard로 학습 동작 확인\n",
        "\n",
        "    - SGD와 같은 간단한 최적화 프로그램과 `tf.distribute.OneDeviceStrategy` 와 같은 간단한 배포 전략을 먼저 사용하십시오.\n",
        "    - 훈련 지표\n",
        "    - 평가 지표\n",
        "    - 고유한 무작위성에 대한 합리적인 허용 오차가 무엇인지 파악\n",
        "\n",
        "    NS. 고급 옵티마이저/학습률 스케줄러/분산 전략으로 동등성 확인\n",
        "\n",
        "    씨. 혼합 정밀도 사용 시 동등성 확인\n",
        "\n",
        "5. 추가 제품 벤치마크"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKakQBI9-FLb"
      },
      "source": [
        "## 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sopP--i7-LaF"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y -q tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1ghHyXl-Oqd"
      },
      "outputs": [],
      "source": [
        "# Install tf-nightly as the DeterministicRandomTestTool is only available in\n",
        "# Tensorflow 2.8\n",
        "!pip install -q tf-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usyRSlIRl3r2"
      },
      "source": [
        "### 단일 정방향 패스 검증\n",
        "\n",
        "체크포인트 로딩을 포함한 단일 정방향 패스 검증은 다른 [colab](./validate_correctness.ipynb) 에서 다룹니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVBQbsZeVL_V"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import unittest\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M104dt7m5cC"
      },
      "source": [
        "### 몇 단계에 대한 모델 학습 수치 동등성 검증"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2Nz2Ni1EkMz"
      },
      "source": [
        "모델 구성을 설정하고 가짜 데이터 세트를 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUxXadzKU9rT"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'input_size': 3,\n",
        "    'num_classes': 3,\n",
        "    'layer_1_size': 2,\n",
        "    'layer_2_size': 2,\n",
        "    'num_train_steps': 100,\n",
        "    'init_lr': 1e-3,\n",
        "    'end_lr': 0.0,\n",
        "    'decay_steps': 1000,\n",
        "    'lr_power': 1.0,\n",
        "}\n",
        "\n",
        "# make a small fixed dataset\n",
        "fake_x = np.ones((2, params['input_size']), dtype=np.float32)\n",
        "fake_y = np.zeros((2, params['num_classes']), dtype=np.int32)\n",
        "fake_y[0][0] = 1\n",
        "fake_y[1][1] = 1\n",
        "\n",
        "step_num = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV_n3Ukmz4Un"
      },
      "source": [
        "TF1.x 모델을 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATa5fzL8mAwl"
      },
      "outputs": [],
      "source": [
        "# Assume there is an existing TF1.x model using estimator API\n",
        "# Wrap the model_fn to log necessary tensors for result comparison\n",
        "class SimpleModelWrapper():\n",
        "  def __init__(self):\n",
        "    self.logged_ops = {}\n",
        "    self.logs = {\n",
        "        'step': [],\n",
        "        'lr': [],\n",
        "        'loss': [],\n",
        "        'grads_and_vars': [],\n",
        "        'layer_out': []}\n",
        "     \n",
        "  def model_fn(self, features, labels, mode, params):\n",
        "      out_1 = tf.compat.v1.layers.dense(features, units=params['layer_1_size'])\n",
        "      out_2 = tf.compat.v1.layers.dense(out_1, units=params['layer_2_size'])\n",
        "      logits = tf.compat.v1.layers.dense(out_2, units=params['num_classes'])\n",
        "      loss = tf.compat.v1.losses.softmax_cross_entropy(labels, logits)\n",
        "\n",
        "      # skip EstimatorSpec details for prediction and evaluation \n",
        "      if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "          pass\n",
        "      if mode == tf.estimator.ModeKeys.EVAL:\n",
        "          pass\n",
        "      assert mode == tf.estimator.ModeKeys.TRAIN\n",
        "\n",
        "      global_step = tf.compat.v1.train.get_or_create_global_step()\n",
        "      lr = tf.compat.v1.train.polynomial_decay(\n",
        "        learning_rate=params['init_lr'],\n",
        "        global_step=global_step,\n",
        "        decay_steps=params['decay_steps'],\n",
        "        end_learning_rate=params['end_lr'],\n",
        "        power=params['lr_power'])\n",
        "      \n",
        "      optmizer = tf.compat.v1.train.GradientDescentOptimizer(lr)\n",
        "      grads_and_vars = optmizer.compute_gradients(\n",
        "          loss=loss,\n",
        "          var_list=graph.get_collection(\n",
        "              tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES))\n",
        "      train_op = optmizer.apply_gradients(\n",
        "          grads_and_vars,\n",
        "          global_step=global_step)\n",
        "      \n",
        "      # log tensors\n",
        "      self.logged_ops['step'] = global_step\n",
        "      self.logged_ops['lr'] = lr\n",
        "      self.logged_ops['loss'] = loss\n",
        "      self.logged_ops['grads_and_vars'] = grads_and_vars\n",
        "      self.logged_ops['layer_out'] = {\n",
        "          'layer_1': out_1,\n",
        "          'layer_2': out_2,\n",
        "          'logits': logits}\n",
        "\n",
        "      return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
        "\n",
        "  def update_logs(self, logs):\n",
        "    for key in logs.keys():\n",
        "      model_tf1.logs[key].append(logs[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kki9yILSKS7f"
      },
      "source": [
        "다음 [`v1.keras.utils.DeterministicRandomTestTool`](https://www.tensorflow.org/api_docs/python/tf/compat/v1/keras/utils/DeterministicRandomTestTool) 클래스는 상태 저장 임의 작업이 TF1 그래프/세션과 즉시 실행 모두에서 동일한 시드를 사용하도록 할 수 있는 컨텍스트 관리자 `scope()`\n",
        "\n",
        "이 도구는 두 가지 테스트 모드를 제공합니다.\n",
        "\n",
        "1. 호출된 횟수에 상관없이 모든 단일 작업에 대해 동일한 시드를 사용하는 `constant`\n",
        "2. 이전에 관찰된 상태 저장 임의 작업의 수를 작업 시드로 사용하는 `num_random_ops`\n",
        "\n",
        "이것은 변수 생성 및 초기화에 사용되는 상태 저장 랜덤 연산과 계산에 사용되는 상태 저장 랜덤 연산(예: 드롭아웃 레이어)에 모두 적용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6Y3RWMoKOl8"
      },
      "outputs": [],
      "source": [
        "random_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk5-ZzxcErX5"
      },
      "source": [
        "그래프 모드에서 TF1.x 모델을 실행합니다. 수치적 동등성 비교를 위해 처음 3개의 훈련 단계에 대한 통계를 수집합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5zhJHvsWA24"
      },
      "outputs": [],
      "source": [
        "with random_tool.scope():\n",
        "  graph = tf.Graph()\n",
        "  with graph.as_default(), tf.compat.v1.Session(graph=graph) as sess:\n",
        "    model_tf1 = SimpleModelWrapper()\n",
        "    # build the model\n",
        "    inputs = tf.compat.v1.placeholder(tf.float32, shape=(None, params['input_size']))\n",
        "    labels = tf.compat.v1.placeholder(tf.float32, shape=(None, params['num_classes']))\n",
        "    spec = model_tf1.model_fn(inputs, labels, tf.estimator.ModeKeys.TRAIN, params)\n",
        "    train_op = spec.train_op\n",
        "\n",
        "    sess.run(tf.compat.v1.global_variables_initializer())\n",
        "    for step in range(step_num):\n",
        "      # log everything and update the model for one step\n",
        "      logs, _ = sess.run(\n",
        "          [model_tf1.logged_ops, train_op],\n",
        "          feed_dict={inputs: fake_x, labels: fake_y})\n",
        "      model_tf1.update_logs(logs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZxjI8Nxz9Ea"
      },
      "source": [
        "TF2 모델을 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA67rh2TkS1M"
      },
      "outputs": [],
      "source": [
        "class SimpleModel(tf.keras.Model):\n",
        "  def __init__(self, params, *args, **kwargs):\n",
        "    super(SimpleModel, self).__init__(*args, **kwargs)\n",
        "    # define the model\n",
        "    self.dense_1 = tf.keras.layers.Dense(params['layer_1_size'])\n",
        "    self.dense_2 = tf.keras.layers.Dense(params['layer_2_size'])\n",
        "    self.out = tf.keras.layers.Dense(params['num_classes'])\n",
        "    learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "      initial_learning_rate=params['init_lr'],\n",
        "      decay_steps=params['decay_steps'],\n",
        "      end_learning_rate=params['end_lr'],\n",
        "      power=params['lr_power'])  \n",
        "    self.optimizer = tf.keras.optimizers.SGD(learning_rate_fn)\n",
        "    self.compiled_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    self.logs = {\n",
        "        'lr': [],\n",
        "        'loss': [],\n",
        "        'grads': [],\n",
        "        'weights': [],\n",
        "        'layer_out': []}\n",
        "\n",
        "  def call(self, inputs):\n",
        "    out_1 = self.dense_1(inputs)\n",
        "    out_2 = self.dense_2(out_1)\n",
        "    logits = self.out(out_2)\n",
        "    # log output features for every layer for comparison\n",
        "    layer_wise_out = {\n",
        "        'layer_1': out_1,\n",
        "        'layer_2': out_2,\n",
        "        'logits': logits}\n",
        "    self.logs['layer_out'].append(layer_wise_out)\n",
        "    return logits\n",
        "\n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = self(x)\n",
        "      loss = self.compiled_loss(y, logits)\n",
        "    grads = tape.gradient(loss, self.trainable_weights)\n",
        "    # log training statistics\n",
        "    step = self.optimizer.iterations.numpy()\n",
        "    self.logs['lr'].append(self.optimizer.learning_rate(step).numpy())\n",
        "    self.logs['loss'].append(loss.numpy())\n",
        "    self.logs['grads'].append(grads)\n",
        "    self.logs['weights'].append(self.trainable_weights)\n",
        "    # update model\n",
        "    self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5smAcaEE8nX"
      },
      "source": [
        "Eager 모드에서 TF2 모델을 실행합니다. 수치적 동등성 비교를 위해 처음 3개의 훈련 단계에 대한 통계를 수집합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0AbXF_eE8cS"
      },
      "outputs": [],
      "source": [
        "random_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')\n",
        "with random_tool.scope():\n",
        "  model_tf2 = SimpleModel(params)\n",
        "  for step in range(step_num):\n",
        "    model_tf2.train_step([fake_x, fake_y])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjJDjLcAz_gU"
      },
      "source": [
        "처음 몇 개의 훈련 단계에 대한 수치적 동등성을 비교합니다.\n",
        "\n",
        "수치 동등성에 대한 추가 조언 [은 Validating 정확성 및 수치 동등성 노트북](./validate_correctness.ipynb) 을 확인할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CbCUbsCiabC"
      },
      "outputs": [],
      "source": [
        "np.testing.assert_allclose(model_tf1.logs['lr'], model_tf2.logs['lr'])\n",
        "np.testing.assert_allclose(model_tf1.logs['loss'], model_tf2.logs['loss'])\n",
        "for step in range(step_num):\n",
        "  for name in model_tf1.logs['layer_out'][step]:\n",
        "    np.testing.assert_allclose(\n",
        "        model_tf1.logs['layer_out'][step][name],\n",
        "        model_tf2.logs['layer_out'][step][name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhVuuciimLIY"
      },
      "source": [
        "#### 단위 테스트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXZYFC6Hhqeb"
      },
      "source": [
        "마이그레이션 코드를 디버그하는 데 도움이 되는 몇 가지 유형의 단위 테스트가 있습니다.\n",
        "\n",
        "1. 단일 정방향 패스 검증\n",
        "2. 몇 단계에 대한 모델 학습 수치 동등성 검증\n",
        "3. 벤치마크 추론 성능\n",
        "4. 훈련된 모델은 고정된 단순 데이터 포인트에 대해 정확한 예측을 수행합니다.\n",
        "\n",
        "`@parameterized.parameters` 를 사용하여 다양한 구성으로 모델을 테스트할 수 있습니다. [코드 샘플이 포함된 세부정보](https://github.com/abseil/abseil-py/blob/master/absl/testing/parameterized.py)\n",
        "\n",
        "동일한 테스트 사례에서 세션 API 및 즉시 실행을 실행할 수 있습니다. 아래의 코드 조각은 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdHqkgPPM2Bj"
      },
      "outputs": [],
      "source": [
        "import unittest\n",
        "\n",
        "class TestNumericalEquivalence(unittest.TestCase):\n",
        "\n",
        "  # copied from code samples above\n",
        "  def setup(self):\n",
        "    # record statistics for 100 training steps\n",
        "    step_num = 100\n",
        "\n",
        "    # setup TF 1 model\n",
        "    random_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')\n",
        "    with random_tool.scope():\n",
        "      # run TF1.x code in graph mode with context management\n",
        "      graph = tf.Graph()\n",
        "      with graph.as_default(), tf.compat.v1.Session(graph=graph) as sess:\n",
        "        self.model_tf1 = SimpleModelWrapper()\n",
        "        # build the model\n",
        "        inputs = tf.compat.v1.placeholder(tf.float32, shape=(None, params['input_size']))\n",
        "        labels = tf.compat.v1.placeholder(tf.float32, shape=(None, params['num_classes']))\n",
        "        spec = self.model_tf1.model_fn(inputs, labels, tf.estimator.ModeKeys.TRAIN, params)\n",
        "        train_op = spec.train_op\n",
        "\n",
        "        sess.run(tf.compat.v1.global_variables_initializer())\n",
        "        for step in range(step_num):\n",
        "          # log everything and update the model for one step\n",
        "          logs, _ = sess.run(\n",
        "              [self.model_tf1.logged_ops, train_op],\n",
        "              feed_dict={inputs: fake_x, labels: fake_y})\n",
        "          self.model_tf1.update_logs(logs)\n",
        "\n",
        "    # setup TF2 model\n",
        "    random_tool = v1.keras.utils.DeterministicRandomTestTool(mode='num_random_ops')\n",
        "    with random_tool.scope():\n",
        "      self.model_tf2 = SimpleModel(params)\n",
        "      for step in range(step_num):\n",
        "        self.model_tf2.train_step([fake_x, fake_y])\n",
        "  \n",
        "  def test_learning_rate(self):\n",
        "    np.testing.assert_allclose(\n",
        "        self.model_tf1.logs['lr'],\n",
        "        self.model_tf2.logs['lr'])\n",
        "\n",
        "  def test_training_loss(self):\n",
        "    # adopt different tolerance strategies before and after 10 steps\n",
        "    first_n_step = 10\n",
        "\n",
        "    # abosolute difference is limited below 1e-5\n",
        "    # set `equal_nan` to be False to detect potential NaN loss issues\n",
        "    abosolute_tolerance = 1e-5\n",
        "    np.testing.assert_allclose(\n",
        "        actual=self.model_tf1.logs['loss'][:first_n_step],\n",
        "        desired=self.model_tf2.logs['loss'][:first_n_step],\n",
        "        atol=abosolute_tolerance,\n",
        "        equal_nan=False)\n",
        "    \n",
        "    # relative difference is limited below 5%\n",
        "    relative_tolerance = 0.05\n",
        "    np.testing.assert_allclose(self.model_tf1.logs['loss'][first_n_step:],\n",
        "                               self.model_tf2.logs['loss'][first_n_step:],\n",
        "                               rtol=relative_tolerance,\n",
        "                               equal_nan=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gshSQdKIddpZ"
      },
      "source": [
        "## 디버깅 도구"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkMfCaJRclKv"
      },
      "source": [
        "### tf.print\n",
        "\n",
        "tf.print 대 인쇄/logging.info\n",
        "\n",
        "- 구성 가능한 인수를 사용하여 `tf.print` 는 인쇄된 텐서에 대한 각 차원의 처음 및 마지막 몇 가지 요소를 재귀적으로 표시할 수 있습니다. 자세한 내용은 [API 문서를 확인하세요.](https://www.tensorflow.org/api_docs/python/tf/print)\n",
        "- 즉시 실행을 위해 `print` 와 `tf.print` 모두 텐서의 값을 출력합니다. 그러나 `print` 에는 잠재적으로 코드 속도를 저하시킬 수 있는 장치-호스트 복사가 포함될 수 있습니다.\n",
        "- `tf.function` 내부 사용을 포함하는 그래프 모드의 경우 실제 텐서 값을 인쇄하려면 `tf.print` `tf.print` 는 그래프의 op로 컴파일되는 반면, `print` 및 `logging.info` 는 추적 시간에만 기록하는데, 이는 종종 원하는 것이 아닙니다.\n",
        "- `tf.print` `tf.RaggedTensor` 및 `tf.sparse.SparseTensor` 와 같은 복합 텐서 인쇄도 지원합니다.\n",
        "- 콜백을 사용하여 메트릭 및 변수를 모니터링할 수도 있습니다. [logs dict](https://www.tensorflow.org/guide/keras/custom_callback#usage_of_logs_dict) 및 [self.model 속성](https://www.tensorflow.org/guide/keras/custom_callback#usage_of_selfmodel_attribute) 과 함께 사용자 정의 콜백을 사용하는 방법을 확인하십시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-5h3cX8Dc50"
      },
      "source": [
        "tf.print 대 tf.function 내부 인쇄"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRED9FMyDKih"
      },
      "outputs": [],
      "source": [
        "# `print` prints info of tensor object\n",
        "# `tf.print` prints the tensor value\n",
        "@tf.function\n",
        "def dummy_func(num):\n",
        "  num += 1\n",
        "  print(num)\n",
        "  tf.print(num)\n",
        "  return num\n",
        "\n",
        "_ = dummy_func(tf.constant([1.0]))\n",
        "\n",
        "# Output:\n",
        "# Tensor(\"add:0\", shape=(1,), dtype=float32)\n",
        "# [2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QroLA_zDK2w"
      },
      "source": [
        "tf.distribute.Strategy\n",
        "\n",
        "- 는 IF `tf.function` 포함 `tf.print` 노동자에 실행 사용하는 경우, 예를 들어 `TPUStrategy` 또는 `ParameterServerStrategy` , 당신은 인쇄 된 값을 찾기 위해 작업자 / 매개 변수의 서버 로그를 확인해야합니다.\n",
        "- `print` 또는 `logging.info` `ParameterServerStrategy` 사용할 때 로그가 코디네이터에 인쇄되고 로그가 TPU를 사용할 때 worker0의 STDOUT에 인쇄됩니다.\n",
        "\n",
        "tf.keras.Model\n",
        "\n",
        "- Sequential 및 Functional API 모델을 사용할 때 일부 레이어 뒤에 모델 입력 또는 중간 기능과 같은 값을 인쇄하려는 경우 다음 옵션이 있습니다.\n",
        "    1. 입력을 `tf.print` [하는 사용자 정의 레이어](https://www.tensorflow.org/guide/keras/custom_layers_and_models) 를 작성하십시오.\n",
        "    2. 모델 출력에 검사하려는 중간 출력을 포함합니다.\n",
        "- `tf.keras.layers.Lambda` 레이어에는 (역)직렬화 제한이 있습니다. 체크포인트 로딩 문제를 피하려면 대신 사용자 정의 서브클래싱된 레이어를 작성하십시오. 자세한 내용은 [API 문서](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda) 를 확인하세요.\n",
        "- 실제 값에 액세스할 수 없고 대신 기호 Keras 텐서 객체에만 액세스할 수 있는 경우 `tf.print` 중간 출력을 `tf.keras.callbacks.LambdaCallback`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKazGTr1ZUMG"
      },
      "source": [
        "옵션 1: 사용자 지정 레이어 작성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w4aY7wO0B4W"
      },
      "outputs": [],
      "source": [
        "class PrintLayer(tf.keras.layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    tf.print(inputs)\n",
        "    return inputs\n",
        "\n",
        "def get_model():\n",
        "  inputs = tf.keras.layers.Input(shape=(1,))\n",
        "  out_1 = tf.keras.layers.Dense(4)(inputs)\n",
        "  out_2 = tf.keras.layers.Dense(1)(out_1)\n",
        "  # use custom layer to tf.print intermediate features\n",
        "  out_3 = PrintLayer()(out_2)\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=out_3)\n",
        "  return model\n",
        "\n",
        "model = get_model()\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit([1, 2, 3], [0.0, 0.0, 1.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNESOatq7iM9"
      },
      "source": [
        "옵션 2: 검사하려는 중간 출력을 모델 출력에 포함합니다.\n",
        "\n",
        "`Model.fit` 을 사용하기 위해 [몇 가지 사용자 정의](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit) 가 필요할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiifvdLk7g9J"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "  inputs = tf.keras.layers.Input(shape=(1,))\n",
        "  out_1 = tf.keras.layers.Dense(4)(inputs)\n",
        "  out_2 = tf.keras.layers.Dense(1)(out_1)\n",
        "  # include intermediate values in model outputs\n",
        "  model = tf.keras.Model(\n",
        "      inputs=inputs,\n",
        "      outputs={\n",
        "          'inputs': inputs,\n",
        "          'out_1': out_1,\n",
        "          'out_2': out_2})\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvIKDZpHSLmQ"
      },
      "source": [
        "### pdb\n",
        "\n",
        "[터미널과 Colab 모두에서 pdb](https://docs.python.org/3/library/pdb.html) 를 사용하여 디버깅을 위해 중간 값을 검사할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu0n4O2umyT7"
      },
      "source": [
        "### TensorBoard로 그래프 시각화\n",
        "\n",
        "[TensorBoard를 사용하여 TensorFlow 그래프를 검사](https://www.tensorflow.org/tensorboard/graphs) 할 수 있습니다. TensorBoard는 colab에서도 [지원됩니다](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks) . TensorBoard는 요약을 시각화하는 훌륭한 도구입니다. 이를 사용하여 학습률, 모델 가중치, 그래디언트 스케일, 학습/검증 메트릭을 비교하거나 학습 프로세스를 통해 TF1.x 모델과 마이그레이션된 TF2 모델 간의 중간 출력을 모델링하고 값이 예상대로 보이는지 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBnxB6_xzlnT"
      },
      "source": [
        "### 텐서플로우 프로파일러\n",
        "\n",
        "[TensorFlow Profiler](https://www.tensorflow.org/guide/profiler) 를 사용하면 GPU/TPU에서 실행 타임라인을 시각화할 수 있습니다. [이 Colab 데모](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras) 에서 기본적인 사용법을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wNmCSHBpiGM"
      },
      "source": [
        "### MultiProcessRunner\n",
        "\n",
        "[MultiProcessRunner](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/distribute/multi_process_runner.py#L108) 는 MultiWorkerMirroredStrategy 및 ParameterServerStrategy로 디버깅할 때 유용한 도구입니다. 사용법에 대한 [이 구체적인 예](https://github.com/keras-team/keras/blob/master/keras/integration_test/mwms_multi_process_runner_test.py) 를 볼 수 있습니다.\n",
        "\n",
        "특히 이 두 가지 전략의 경우 1) 흐름을 커버하는 단위 테스트를 가질 뿐만 아니라 2) 시도할 때마다 실제 분산 작업을 시작하지 않도록 단위 테스트에서 이를 사용하여 실패를 재현하는 것이 좋습니다. 수정."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "migration_debugging.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
